# ğŸ§ª GUIDE D'UTILISATION - TEST DE CHARGE

## ğŸ“‹ PRÃ‰-REQUIS

Avant d'utiliser le script de test de charge, assurez-vous d'avoir :

1. âœ… **kubectl** configurÃ© et connectÃ© Ã  votre cluster EKS
   ```bash
   kubectl get nodes
   ```

2. âœ… **Application dÃ©ployÃ©e** (les 12 microservices doivent Ãªtre Running)
   ```bash
   kubectl get pods
   ```

3. âœ… **HPAs configurÃ©s** (optionnel mais recommandÃ©)
   ```bash
   kubectl get hpa
   ```

---

## ğŸš€ UTILISATION DU SCRIPT

### Lancer un Test de Charge

```bash
./test-de-charge.sh
```

Le script est **100% interactif** et vous guide Ã  travers 5 Ã©tapes :

#### 1ï¸âƒ£ **Configuration**
Choisissez le nombre d'utilisateurs :
- 1000 utilisateurs (10 loadgenerators)
- 2000 utilisateurs (20 loadgenerators)
- 5000 utilisateurs (50 loadgenerators) âš ï¸ Charge Ã©levÃ©e
- 10000 utilisateurs (100 loadgenerators) ğŸ”¥ TrÃ¨s haute charge
- Nombre personnalisÃ©

#### 2ï¸âƒ£ **CrÃ©ation du YAML**
Le script crÃ©e automatiquement le fichier `loadgenerator-XXXX.yaml` si nÃ©cessaire.

#### 3ï¸âƒ£ **VÃ©rification Infrastructure**
- Affiche l'Ã©tat actuel (nodes, pods)
- Propose de configurer les HPAs si manquants

#### 4ï¸âƒ£ **DÃ©ploiement**
- Applique le YAML
- Attend le dÃ©marrage des pods (barre de progression)

#### 5ï¸âƒ£ **Surveillance en Temps RÃ©el** ğŸ”¥
Affiche toutes les 5 secondes :
- Nombre de loadgenerators actifs
- Utilisateurs simulÃ©s
- Ã‰tat des HPAs (auto-scaling)
- Nombre de pods par service
- Nombre de nodes
- Top 5 pods par CPU

**Appuyez sur `Ctrl+C` pour quitter la surveillance** (le test continue en arriÃ¨re-plan)

---

## ğŸ›‘ ARRÃŠTER UN TEST

### Option 1 : Script d'ArrÃªt (RECOMMANDÃ‰)

```bash
./stop-test.sh loadgenerator-test-5000
```

Vous aurez le choix :
1. ArrÃªt progressif (recommandÃ©)
2. ArrÃªt immÃ©diat
3. Suppression complÃ¨te
4. Annuler

### Option 2 : Commandes Manuelles

**ArrÃªt progressif** :
```bash
# RÃ©duire Ã  50%
kubectl scale deployment loadgenerator-test-5000 --replicas=25

# RÃ©duire Ã  1000 users
kubectl scale deployment loadgenerator-test-5000 --replicas=10

# ArrÃªt total
kubectl scale deployment loadgenerator-test-5000 --replicas=0
```

**ArrÃªt immÃ©diat** :
```bash
kubectl scale deployment loadgenerator-test-5000 --replicas=0
```

**Suppression complÃ¨te** :
```bash
kubectl delete deployment loadgenerator-test-5000
```

---

## ğŸ“Š SURVEILLANCE MANUELLE

### Surveiller les HPAs (Auto-Scaling)

```bash
watch kubectl get hpa
```

### Surveiller les Nodes

```bash
watch kubectl get nodes
```

### Voir tous les Pods

```bash
watch kubectl get pods
```

### MÃ©triques CPU/RAM

```bash
# Pods
kubectl top pods

# Nodes
kubectl top nodes

# Top 10 pods par CPU
kubectl top pods --sort-by=cpu | head -10
```

### Voir les Loadgenerators Actifs

```bash
kubectl get pods -l app=loadgenerator-test-5000
```

### Logs des Loadgenerators

```bash
kubectl logs -l app=loadgenerator-test-5000 --tail=50
```

---

## ğŸ¯ SCÃ‰NARIOS D'UTILISATION

### ScÃ©nario 1 : Test Rapide (1000 users)

```bash
./test-de-charge.sh
# Choix : 1
# Confirmer : o
# Attendre 5 minutes
# Ctrl+C pour arrÃªter la surveillance
# ./stop-test.sh loadgenerator-test-1000
```

**RÃ©sultat attendu** :
- Nodes : 3-5
- Pods frontend : 2-5
- DurÃ©e recommandÃ©e : 10-15 minutes
- CoÃ»t : ~2 USD

### ScÃ©nario 2 : Test Moyen (5000 users)

```bash
./test-de-charge.sh
# Choix : 3
# Confirmer : o
# Attendre 10-15 minutes
# Observer le scaling
# Ctrl+C pour arrÃªter la surveillance
# ./stop-test.sh loadgenerator-test-5000
```

**RÃ©sultat attendu** :
- Nodes : 15-25
- Pods frontend : 10-20
- Pods catalog : 5-10
- DurÃ©e recommandÃ©e : 30-60 minutes
- CoÃ»t : ~6-10 USD

### ScÃ©nario 3 : Stress Test (10000 users)

```bash
./test-de-charge.sh
# Choix : 4
# Confirmer : o
# Attendre 20-30 minutes
# Observer les limites du cluster
# Ctrl+C pour arrÃªter la surveillance
# ./stop-test.sh loadgenerator-test-10000
```

**RÃ©sultat attendu** :
- Nodes : 30-50
- Pods frontend : 15-20 (max)
- Pods catalog : 8-10 (max)
- DurÃ©e recommandÃ©e : 1-2 heures
- CoÃ»t : ~15-25 USD
- âš ï¸ Peut atteindre les limites du cluster (65 nodes max)

---

## âš ï¸ NOTES IMPORTANTES

### CoÃ»ts AWS

Les tests de charge **coÃ»tent de l'argent** :
- **1000 users** : ~2 USD pour 1h de test
- **5000 users** : ~6-10 USD pour 1h de test
- **10000 users** : ~15-25 USD pour 1h de test

**N'oubliez pas d'arrÃªter les tests aprÃ¨s utilisation !**

### Cluster Autoscaler

Le Cluster Autoscaler va :
- **Scale UP** : Ajouter des nodes quand les pods sont en `Pending`
- **Scale DOWN** : Retirer des nodes sous-utilisÃ©s aprÃ¨s ~10 minutes

**Le scale down est automatique mais peut prendre 10-15 minutes.**

### Limites du Cluster

Configuration actuelle :
- **Min nodes** : 3
- **Max nodes** : 65
- **Max pods par node** : ~29 (limite AWS ENI)

Si vous atteignez 65 nodes, les nouveaux pods resteront en `Pending`.

---

## ğŸ”§ DÃ‰PANNAGE

### ProblÃ¨me : "kubectl: command not found"

```bash
# Installer kubectl
brew install kubectl

# Ou tÃ©lÃ©charger depuis
# https://kubernetes.io/docs/tasks/tools/
```

### ProblÃ¨me : "error: You must be logged in to the server"

```bash
# Reconfigurer kubectl
aws eks update-kubeconfig --region eu-south-2 --name eks-bfs-gp12-prod
```

### ProblÃ¨me : Pods en "ImagePullBackOff"

Les images sont dans le Google Container Registry et sont publiques. Si erreur :
```bash
# VÃ©rifier les images
kubectl describe pod <nom-du-pod>

# Les images doivent Ãªtre :
# gcr.io/google-samples/microservices-demo/loadgenerator:v0.10.1
```

### ProblÃ¨me : Pods en "Pending" longtemps

```bash
# VÃ©rifier les Ã©vÃ©nements
kubectl get events --sort-by='.lastTimestamp' | tail -20

# VÃ©rifier le Cluster Autoscaler
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=50

# Peut prendre 3-5 minutes pour ajouter des nodes
```

### ProblÃ¨me : "bc: command not found"

Le script utilise `bc` pour la barre de progression. Installer :
```bash
# macOS
brew install bc

# Ubuntu/Debian
sudo apt-get install bc
```

---

## ğŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S

Lors de l'exÃ©cution, le script crÃ©e :
- `loadgenerator-1000.yaml` (si choix 1)
- `loadgenerator-2000.yaml` (si choix 2)
- `loadgenerator-5000.yaml` (si choix 3)
- `loadgenerator-10000.yaml` (si choix 4)
- `loadgenerator-XXXX.yaml` (si personnalisÃ©)

Ces fichiers peuvent Ãªtre :
- âœ… **CommittÃ©s** dans Git (templates)
- âœ… **RÃ©utilisÃ©s** pour relancer le mÃªme test
- âœ… **ModifiÃ©s** pour ajuster la configuration

---

## ğŸ“ˆ MÃ‰TRIQUES Ã€ OBSERVER

### Indicateurs de SantÃ© âœ…

- **Pods** : Tous en `Running`, pas de `CrashLoopBackOff`
- **HPAs** : Scaling progressif et fluide
- **Nodes** : Ajout progressif selon les besoins
- **CPU** : 60-80% moyen (optimal)
- **RAM** : 70-80% moyen (optimal)

### Signaux d'Alerte âš ï¸

- **Pods Pending** > 5 minutes : Cluster Autoscaler lent ou limite atteinte
- **CPU > 90%** : Risque de throttling, besoin de plus de resources
- **Pods CrashLoopBackOff** : ProblÃ¨me applicatif, saturation mÃ©moire
- **Nodes non ajoutÃ©s** : VÃ©rifier les logs du Cluster Autoscaler

---

## ğŸ¯ CHECKLIST AVANT TEST

- [ ] kubectl configurÃ© et connectÃ©
- [ ] Application dÃ©ployÃ©e (12 microservices Running)
- [ ] HPAs configurÃ©s (5 services)
- [ ] Cluster Autoscaler opÃ©rationnel
- [ ] Metrics Server fonctionnel
- [ ] Budget AWS validÃ© pour le test

---

## ğŸ“ SUPPORT

### VÃ©rifier l'Ã‰tat du Cluster

```bash
# Nodes
kubectl get nodes

# Pods
kubectl get pods

# Services
kubectl get services

# HPAs
kubectl get hpa

# Cluster Autoscaler
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=50
```

### Logs CloudWatch

```bash
# Via AWS CLI
aws logs tail /aws/eks/eks-bfs-gp12-prod/cluster --follow

# Via Console
# https://eu-south-2.console.aws.amazon.com/cloudwatch/
```

---

## ğŸ“š DOCUMENTATION ADDITIONNELLE

- `TESTS-CHARGE-5K-PROGRESSIF.md` - Guide dÃ©taillÃ© tests 5K
- `TESTS-CHARGE-1000-USERS.md` - Guide tests 1K
- `ETAT-RESSOURCES-AWS.md` - Ã‰tat complet de l'infrastructure
- `RAPPORT-PROGRESSION.md` - Progression du projet

---

**Script crÃ©Ã© par** : Black Friday Survival Team  
**Version** : 1.0  
**Date** : FÃ©vrier 2026  
**Cluster** : eks-bfs-gp12-prod  
**RÃ©gion** : eu-south-2 (Espagne)

ğŸš€ **Bon test de charge !**

